{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **NLP: Classifying Text**\n",
    "\n",
    "**Submitted by:** Euclides\n",
    "\n",
    "**Course:** CUNY DATA 620\n",
    "\n",
    "**Data Source:** NLTK Names Package Corpus "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Introduction**\n",
    "\n",
    "Using the 'Names' corpus embedded in the NLTK package an algorithm is developed to identify whether a name is either male or femae. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import names\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'fileids'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mnames\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfileids\u001b[49m()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'fileids'"
     ]
    }
   ],
   "source": [
    "names.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ([(name, 'male') for name in names.words('male.txt')]+\n",
    "         [(name, 'female') for name in names.words('female.txt')])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Aamir', 'male'),\n",
       " ('Aaron', 'male'),\n",
       " ('Abbey', 'male'),\n",
       " ('Abbie', 'male'),\n",
       " ('Abbot', 'male'),\n",
       " ('Abbott', 'male'),\n",
       " ('Abby', 'male'),\n",
       " ('Abdel', 'male'),\n",
       " ('Abdul', 'male'),\n",
       " ('Abdulkarim', 'male')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Gabrila', 'female'),\n",
       " ('Rosario', 'female'),\n",
       " ('Annabella', 'female'),\n",
       " ('Mead', 'female'),\n",
       " ('Pepe', 'male'),\n",
       " ('Malina', 'female'),\n",
       " ('Kaari', 'female'),\n",
       " ('Gabbie', 'female'),\n",
       " ('Tatiania', 'female'),\n",
       " ('Philippine', 'female')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.seed(10)\n",
    "random.shuffle(names)\n",
    "names[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Corpus: 7944\n"
     ]
    }
   ],
   "source": [
    "#Length of tuple list\n",
    "print(\"Length of Corpus:\", len(names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train Set, Dev Set, Test Set \n",
    "train_names = names[:500] #First Random 500\n",
    "dev_names = names[500:1000] #Next Random 500\n",
    "test_names = names[1000:] #Balance of words for Test Set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature 1: First Letter \n",
    "def gender_feature1(word):\n",
    "    return {'first letter': word[0]}\n",
    "\n",
    "#Feature 2: First Two Letters   \n",
    "def gender_feature2(word):\n",
    "    return {'prefix1': word[0],\n",
    "            'prefix2': word[1]}\n",
    "\n",
    "#Feature 3: Last Letter \n",
    "def gender_feature3(word):\n",
    "    return {'last letter': word[-1]}\n",
    "\n",
    "#Feature 4: Last Two Letters \n",
    "def gender_feature4(word):\n",
    "    return {'suffix1': word[-1],\n",
    "            'suffix2': word[-2]}\n",
    "\n",
    "#Feature 4: First and Last Letter\n",
    "def gender_feature5(word):\n",
    "    return {'suffix1': word[-1],\n",
    "            'prefix1': word[0]}\n",
    "\n",
    "#Create a list of functions     \n",
    "functions = [gender_feature1, gender_feature2, gender_feature3, gender_feature4, gender_feature5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 1 Accuracy on Development Set:  0.61\n",
      "Feature 2 Accuracy on Development Set:  0.606\n",
      "Feature 3 Accuracy on Development Set:  0.734\n",
      "Feature 4 Accuracy on Development Set:  0.752\n",
      "Feature 5 Accuracy on Development Set:  0.774\n"
     ]
    }
   ],
   "source": [
    "#Loop to test all features on development list \n",
    "i = 1\n",
    "for features in functions:\n",
    "    train_set = [(features(n), g) for (n,g) in train_names]\n",
    "    devtest_set = [(features(n), g) for (n,g) in dev_names]\n",
    "    classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "    print (\"Feature\",i, \"Accuracy on Development Set: \",nltk.classify.accuracy(classifier, devtest_set)) \n",
    "    i= i + 1\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature 5 Accuracy on Test Set:  0.7602\n"
     ]
    }
   ],
   "source": [
    "train_set = [(features(n), g) for (n,g) in train_names]\n",
    "test_set = [(features(n), g) for (n,g) in test_names]\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "print(\"Feature 5 Accuracy on Test Set: \",round(nltk.classify.accuracy(classifier, test_set),4))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
